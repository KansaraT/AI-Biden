{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewuASwtomQnF"
      },
      "source": [
        "### Part1: Generating text responses using LLM\n",
        "In this part we are generating responses to the questions asked to president Biden in the 'first 2024 presidential debate between Joe Biden and Donald Trump'. The text responses are generated using pre-trained OpenAI LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbO-vjjnmHfI"
      },
      "outputs": [],
      "source": [
        "# Install the library\n",
        "%%capture\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA_9ZtFW-pKc",
        "outputId": "08174ab2-d021-430b-c7f3-64a7a9d8bdf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My approach to handling the conflict in Ukraine is grounded in diplomacy, support for Ukraine's sovereignty, and working closely with our allies and partners. It is essential to engage in dialogue, uphold international agreements, and seek peaceful solutions through negotiation and dialogue. The United States stands with Ukraine in its efforts to defend its territorial integrity and build a more stable and secure future for its people.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "OPENAI_API_KEY = 'your_openai_api_key'\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key= OPENAI_API_KEY,  # this is also the default, it can be omitted\n",
        ")\n",
        "\n",
        "def generate_response(question, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=200):\n",
        "\n",
        "    # Make the API request to OpenAI\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI simulation designed to emulate President Joe Biden, providing articulate and insightful responses to a series of questions. \\\n",
        "                                           Your task is to respond to the same questions that President Biden recently received in a public forum. \\\n",
        "                                           Your responses should demonstrate a deep understanding of the issues discussed, convey empathy and clarity in your communication style, and exhibit a high level of coherence.\\\n",
        "                                           Make sure you don't leave the response sentence incomplete.\"},\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    # Extract the response text\n",
        "    answer = response.choices[0].message.content\n",
        "    return answer\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    question = \"What is your approach to handling the conflict in Ukraine?\"\n",
        "    response = generate_response(question)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7KQ3DKZo97t"
      },
      "source": [
        "### Part 2: Cloning Biden's voice in a TTS model\n",
        "In this part we have cloned the voice of president Biden using his one video clip of less than 3 min. And then we generate the audio of the above response.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNVMEHxe-dNQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install TTS\n",
        "!pip install TTS.api\n",
        "!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUUqIZfk-r8y",
        "outputId": "146459e1-2365-4548-eb17-69db6b1929b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
            " > Using model: xtts\n"
          ]
        }
      ],
      "source": [
        "#once the model is loaded, no need to run the cell again.\n",
        "from TTS.api import TTS\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "9T5Ebvk4-sy3",
        "outputId": "4d6bc1f9-3c1c-4d42-8965-d3da0bb7b5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Text splitted to sentences.\n",
            "[\"My approach to handling the conflict in Ukraine is grounded in diplomacy, support for Ukraine's sovereignty, and working closely with our allies and partners.\", 'It is essential to engage in dialogue, uphold international agreements, and seek peaceful solutions through negotiation and dialogue.', 'The United States stands with Ukraine in its efforts to defend its territorial integrity and build a more stable and secure future for its people.']\n",
            " > Processing time: 21.272592544555664\n",
            " > Real-time factor: 0.6024844653705538\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bidenoutput_question4.wav'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# generate speech by cloning a voice using default settings\n",
        "tts.tts_to_file(text=response,\n",
        "                file_path=\"bidenoutput_question4.wav\",\n",
        "                speaker_wav=[\"/content/bidenOriginalVoice.wav\"],\n",
        "                language=\"en\",\n",
        "                #split_sentences=True\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjdUz_OOBD2s"
      },
      "source": [
        "Save the audio files for future use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86Y4SZlrt0Vc"
      },
      "source": [
        "### Part 3: Generating AI Biden\n",
        "In this part we are generating Artificially Intellegent Biden bot who can produce more coherent and effective responses compared to the real President Biden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdvLwoqA89P"
      },
      "source": [
        "Before continue running the next code restart the session once in order to avoid any locale issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YgdAVeSbWH6",
        "outputId": "724af867-6584-45cf-ed80-bb8e62b2d226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 378, done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 0 (delta 0), pack-reused 378\u001b[K\n",
            "Receiving objects: 100% (378/378), 526.97 KiB | 4.50 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zabique/Wav2Lip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E75uTmt2NlC"
      },
      "source": [
        "Make sure to do the following changes before proceeding:\n",
        "\n",
        "In '/content/Wav2Lip/audio.py' change the function '_built_mel_basis()' with the below code.\n",
        "```\n",
        "def _build_mel_basis():\n",
        "    assert hp.fmax <= hp.sample_rate // 2\n",
        "    return librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft, n_mels=hp.num_mels, fmin=hp.fmin, fmax=hp.fmax)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSGwV4h6bWK1",
        "outputId": "20951e35-98e3-4e08-aa51-4f677714edcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-15 06:24:02--  https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA\n",
            "Resolving iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435801865 (416M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’\n",
            "\n",
            "/content/Wav2Lip/ch 100%[===================>] 415.61M  71.3MB/s    in 9.4s    \n",
            "\n",
            "2024-07-15 06:24:12 (44.2 MB/s) - ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’ saved [435801865/435801865]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t4yqpqzdChW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!cd Wav2Lip && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQlO-5Xomene",
        "outputId": "4b9de3dd-4bda-4113-ec1e-aca827a4c56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-15 06:25:51--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "/content/Wav2Lip/fa 100%[===================>]  85.68M  24.4MB/s    in 3.7s    \n",
            "\n",
            "2024-07-15 06:25:56 (23.4 MB/s) - ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECka-8bjmero",
        "outputId": "a96d8cef-a003-40d4-9d47-dd9c59719e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 3410\n",
            "(80, 2377)\n",
            "Length of mel chunks: 886\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            "  0% 0/56 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/56 [02:32<2:19:51, 152.58s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "# Get a sample video for providing background and the audio response.\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/bidenVideo.mp4\" --audio \"/content/bidenoutput_question4.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "EGpV5ENemeu3",
        "outputId": "c78e19ac-6a8d-4081-cd88-7e488ed16403"
      },
      "outputs": [],
      "source": [
        "#Play result video -  50% scaling\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2YhIjNKGfELt",
        "outputId": "c8dc2e02-1813-429d-d279-d5e7c097cf09"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a2a89db8-09c1-49d0-8ae4-6e4063fb73d3\", \"result_voice.mp4\", 6265135)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Download Result.mp4 to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/Wav2Lip/results/result_voice.mp4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftChVIpQ5ey0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
